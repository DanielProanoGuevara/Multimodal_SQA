{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.signal\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset\n",
    "train_df = pd.read_pickle('../train_physionet_2016.pkl')\n",
    "val_df = pd.read_pickle('../validation_physionet_2016.pkl')\n",
    "test_df = pd.read_pickle('../test_physionet_2016.pkl')\n",
    "\n",
    "# Convert the loaded DataFrame to the desired numpy format\n",
    "train_data = []\n",
    "for index, row in train_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    train_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels])\n",
    "\n",
    "val_data = []\n",
    "for index, row in val_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    val_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels])\n",
    "\n",
    "test_data = []\n",
    "for index, row in val_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    test_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels])\n",
    "\n",
    "# Convert train_data to a numpy array with dtype=object to handle mixed types\n",
    "train = np.array(train_data, dtype=object)\n",
    "val = np.array(val_data, dtype=object)\n",
    "test = np.array(test_data, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Smaller than patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_smaller_than_patch(features, patch_size):\n",
    "    # Remove sounds shorter than patch size and return their indices\n",
    "    return np.array([j for j in range(len(features)) if len(features[j]) >= patch_size], dtype=int)\n",
    "\n",
    "patch_size = 64\n",
    "nch = 4\n",
    "stride = 32\n",
    "\n",
    "# Ensure indices are integers and apply them correctly to filter the datasets\n",
    "train_indices = filter_smaller_than_patch(train[:,2], patch_size)\n",
    "val_indices = filter_smaller_than_patch(val[:,2], patch_size)\n",
    "test_indices = filter_smaller_than_patch(test[:,2], patch_size)\n",
    "\n",
    "train = train[train_indices, ...]\n",
    "val = val[val_indices, ...]\n",
    "test = test[test_indices, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGDataPreparer:\n",
    "    def __init__(self, patch_size: int , stride: int, number_channels: int=4, num_states: int=4):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.number_channels = number_channels\n",
    "        self.num_states = num_states\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "\n",
    "    def _compute_pcg_patches(self, sound, label):\n",
    "        #TODO: ask them to implement this\n",
    "        num_samples = len(sound)\n",
    "        # TODO: they should complete this for\n",
    "        num_windows = int((num_samples - self.patch_size) / self.stride) + 1\n",
    "        for window_idx in range(num_windows):\n",
    "            patch_start = window_idx * self.stride\n",
    "            yield sound[patch_start:patch_start + self.patch_size, :],  label[patch_start: patch_start + self.patch_size, :]\n",
    "\n",
    "        window_remain = num_samples - self.patch_size\n",
    "        if window_remain % self.stride > 0:\n",
    "          yield sound[window_remain:, :], label[window_remain:, :]\n",
    "\n",
    "    def set_features_and_labels(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        num_observations = len(self.features)\n",
    "        total_windows = 0\n",
    "        for obs in features:\n",
    "          num_samples = len(features)\n",
    "          num_windows = int((num_samples - self.patch_size) / self.stride) + 1\n",
    "          window_remain = num_samples - self.patch_size\n",
    "          if window_remain % self.stride > 0:\n",
    "              num_windows += 1\n",
    "          total_windows += num_windows\n",
    "        self.num_steps = total_windows\n",
    "\n",
    "    def __call__(self):\n",
    "        num_observations = len(self.labels)\n",
    "        for obs_idx in range(num_observations):\n",
    "            features = tf.stack(self.features[obs_idx], axis=1) # np.column_stack\n",
    "            labels = self.labels[obs_idx]\n",
    "            for s,y in (self._compute_pcg_patches(features, labels)):\n",
    "              yield s, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Data Preparers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size = 64\n",
    "nch = 4\n",
    "stride = 32\n",
    "train_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "train_dp.set_features_and_labels(train[:, [1,2,3,4]], train[:, 5])\n",
    "\n",
    "val_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "val_dp.set_features_and_labels(val[:, [1,2,3,4]], val[:, 5])\n",
    "\n",
    "test_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "test_dp.set_features_and_labels(test[:, [1,2,3,4]], test[:, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Dataset and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_data_from_generator(*, data_processor, batch_size, patch_size, number_channels, number_classes, trainable=True):\n",
    "    data = tf.data.Dataset.from_generator(data_processor,\n",
    "                                          output_signature=(\n",
    "                                              tf.TensorSpec(shape=(patch_size, number_channels), dtype=tf.float32),\n",
    "                                              tf.TensorSpec(shape=(patch_size, number_classes), dtype=tf.float32))\n",
    "                                          )\n",
    "    if trainable:\n",
    "        data = data.shuffle(5000, reshuffle_each_iteration=True)\n",
    "        data.cache()\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "train_dataset = get_data_from_generator(data_processor=train_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=True)\n",
    "\n",
    "\n",
    "val_dataset = get_data_from_generator(data_processor=val_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=False)\n",
    "\n",
    "test_dataset = get_data_from_generator(data_processor=test_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, UpSampling1D, concatenate\n",
    "\n",
    "# TODO: provide u-net with one encoder layer only and suggest for them to\n",
    "# increase its size.\n",
    "def unet_pcg(nch, patch_size, dropout=0.0):\n",
    "    inputs = tf.keras.layers.Input(shape=(patch_size, nch))\n",
    "    conv1 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "    pool1 = tf.keras.layers.Dropout(dropout)(pool1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
    "    pool2 = tf.keras.layers.Dropout(dropout)(pool2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv3)\n",
    "    pool3 = tf.keras.layers.Dropout(dropout)(pool3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(dropout)(pool4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6_prep = tf.keras.layers.UpSampling1D(size=2)(conv5)\n",
    "\n",
    "    up6 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(64, 2, padding='same')(up6_prep), conv4], axis=2)\n",
    "    up6 = tf.keras.layers.Dropout(dropout)(up6)\n",
    "    conv6 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7_prep = tf.keras.layers.UpSampling1D(size=2)(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(64, 2, padding='same')(up7_prep), conv3], axis=2)\n",
    "    up7 = tf.keras.layers.Dropout(dropout)(up7)\n",
    "    conv7 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8_prep = tf.keras.layers.UpSampling1D(size=2)(conv7)\n",
    "\n",
    "    up8 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(32, 2, padding='same')(up8_prep), conv2], axis=2)\n",
    "    up8 = tf.keras.layers.Dropout(dropout)(up8)\n",
    "    conv8 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9_prep = tf.keras.layers.UpSampling1D(size=2)(conv8)\n",
    "\n",
    "    up9 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(8, 2, padding='same')(up9_prep), conv1], axis=2)\n",
    "    up9 = tf.keras.layers.Dropout(dropout)(up9)\n",
    "    conv9 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = tf.keras.layers.Conv1D(8, 3, activation='tanh', padding='same')(conv9)\n",
    "\n",
    "    conv10 = tf.keras.layers.Conv1D(4, 1, activation='softmax')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2052/2052 [==============================] - 292s 141ms/step - loss: 0.5927 - categorical_accuracy: 0.7958 - precision: 0.9310 - recall: 0.5808 - val_loss: 0.4701 - val_categorical_accuracy: 0.8477 - val_precision: 0.9237 - val_recall: 0.6674\n",
      "Epoch 2/10\n",
      "2052/2052 [==============================] - 272s 132ms/step - loss: 0.3942 - categorical_accuracy: 0.8673 - precision: 0.9436 - recall: 0.6869 - val_loss: 0.4423 - val_categorical_accuracy: 0.8504 - val_precision: 0.9237 - val_recall: 0.6811\n",
      "Epoch 3/10\n",
      "2052/2052 [==============================] - 279s 136ms/step - loss: 0.3661 - categorical_accuracy: 0.8743 - precision: 0.9470 - recall: 0.6953 - val_loss: 0.4181 - val_categorical_accuracy: 0.8588 - val_precision: 0.9296 - val_recall: 0.6810\n",
      "Epoch 4/10\n",
      "2052/2052 [==============================] - 273s 133ms/step - loss: 0.3526 - categorical_accuracy: 0.8779 - precision: 0.9496 - recall: 0.6986 - val_loss: 0.4208 - val_categorical_accuracy: 0.8577 - val_precision: 0.9289 - val_recall: 0.6879\n",
      "Epoch 5/10\n",
      "2052/2052 [==============================] - 265s 128ms/step - loss: 0.3446 - categorical_accuracy: 0.8799 - precision: 0.9508 - recall: 0.7008 - val_loss: 0.4091 - val_categorical_accuracy: 0.8634 - val_precision: 0.9318 - val_recall: 0.6853\n",
      "Epoch 6/10\n",
      "2052/2052 [==============================] - 268s 130ms/step - loss: 0.3386 - categorical_accuracy: 0.8816 - precision: 0.9521 - recall: 0.7024 - val_loss: 0.4114 - val_categorical_accuracy: 0.8601 - val_precision: 0.9297 - val_recall: 0.6862\n",
      "Epoch 7/10\n",
      "2052/2052 [==============================] - 291s 141ms/step - loss: 0.3336 - categorical_accuracy: 0.8831 - precision: 0.9532 - recall: 0.7038 - val_loss: 0.4036 - val_categorical_accuracy: 0.8631 - val_precision: 0.9318 - val_recall: 0.6877\n",
      "Epoch 8/10\n",
      "2052/2052 [==============================] - 279s 135ms/step - loss: 0.3295 - categorical_accuracy: 0.8842 - precision: 0.9542 - recall: 0.7048 - val_loss: 0.4001 - val_categorical_accuracy: 0.8641 - val_precision: 0.9330 - val_recall: 0.6871\n",
      "Epoch 9/10\n",
      "2052/2052 [==============================] - 263s 127ms/step - loss: 0.3259 - categorical_accuracy: 0.8852 - precision: 0.9549 - recall: 0.7058 - val_loss: 0.4080 - val_categorical_accuracy: 0.8629 - val_precision: 0.9320 - val_recall: 0.6892\n",
      "Epoch 10/10\n",
      "2052/2052 [==============================] - 283s 137ms/step - loss: 0.3225 - categorical_accuracy: 0.8864 - precision: 0.9557 - recall: 0.7069 - val_loss: 0.4013 - val_categorical_accuracy: 0.8631 - val_precision: 0.9326 - val_recall: 0.6879\n"
     ]
    }
   ],
   "source": [
    "# tune hyperpararmeter, epochs, e optimizer\n",
    "# choose adequate metrics\n",
    "# loss crossentropy, others?\n",
    "checkpoint_path = './unet_weights/checkpoint.keras'\n",
    "EPOCHS = 10\n",
    "learning_rate = 1e-4\n",
    "model = unet_pcg(nch, patch_size)\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy',\n",
    "                  metrics=['CategoricalAccuracy', 'Precision', 'Recall'])\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    # steps_per_epoch = int(np.floor(train_dp.num_steps / BATCH_SIZE)),\n",
    "                    verbose=1,\n",
    "                    shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
