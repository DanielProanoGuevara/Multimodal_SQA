{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import librosa\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import scipy.signal\n",
    "import re\n",
    "\n",
    "import pickle\n",
    "\n",
    "from scipy.io import wavfile\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the train dataset\n",
    "train_df = pd.read_pickle('../train_physionet_2016.pkl')\n",
    "val_df = pd.read_pickle('../validation_physionet_2016.pkl')\n",
    "#test_df = pd.read_pickle('../test_physionet_2016.pkl')\n",
    "\n",
    "# Convert the loaded DataFrame to the desired numpy format\n",
    "train_data = []\n",
    "for index, row in train_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    train_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels])\n",
    "\n",
    "val_data = []\n",
    "for index, row in val_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    val_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels])\n",
    "\n",
    "\"\"\" test_data = []\n",
    "for index, row in val_df.iterrows():\n",
    "    patient_id = row['Patient ID']\n",
    "    homomorphic = row['Homomorphic']\n",
    "    cwt_morl = row['CWT_Morl']\n",
    "    cwt_mexh = row['CWT_Mexh']\n",
    "    hilbert_env = row['Hilbert_Env']\n",
    "    labels = row['Labels']\n",
    "\n",
    "    # Append each patient's data as a tuple to the train_data list\n",
    "    test_data.append([patient_id, homomorphic, cwt_morl, cwt_mexh, hilbert_env, labels]) \"\"\"\n",
    "\n",
    "# Convert train_data to a numpy array with dtype=object to handle mixed types\n",
    "train = np.array(train_data, dtype=object)\n",
    "val = np.array(val_data, dtype=object)\n",
    "#test = np.array(test_data, dtype=object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering Smaller than patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_smaller_than_patch(features, patch_size):\n",
    "    # Remove sounds shorter than patch size and return their indices\n",
    "    return np.array([j for j in range(len(features)) if len(features[j]) >= patch_size], dtype=int)\n",
    "\n",
    "patch_size = 64\n",
    "nch = 4\n",
    "stride = 32\n",
    "\n",
    "# Ensure indices are integers and apply them correctly to filter the datasets\n",
    "train_indices = filter_smaller_than_patch(train[:,2], patch_size)\n",
    "val_indices = filter_smaller_than_patch(val[:,2], patch_size)\n",
    "#test_indices = filter_smaller_than_patch(test[:,2], patch_size)\n",
    "\n",
    "train = train[train_indices, ...]\n",
    "val = val[val_indices, ...]\n",
    "#test = test[test_indices, ...]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCGDataPreparer:\n",
    "    def __init__(self, patch_size: int , stride: int, number_channels: int=4, num_states: int=4):\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.number_channels = number_channels\n",
    "        self.num_states = num_states\n",
    "        self.features = None\n",
    "        self.labels = None\n",
    "\n",
    "    def _compute_pcg_patches(self, sound, label):\n",
    "        #TODO: ask them to implement this\n",
    "        num_samples = len(sound)\n",
    "        # TODO: they should complete this for\n",
    "        num_windows = int((num_samples - self.patch_size) / self.stride) + 1\n",
    "        for window_idx in range(num_windows):\n",
    "            patch_start = window_idx * self.stride\n",
    "            yield sound[patch_start:patch_start + self.patch_size, :],  label[patch_start: patch_start + self.patch_size, :]\n",
    "\n",
    "        window_remain = num_samples - self.patch_size\n",
    "        if window_remain % self.stride > 0:\n",
    "          yield sound[window_remain:, :], label[window_remain:, :]\n",
    "\n",
    "    def set_features_and_labels(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "        num_observations = len(self.features)\n",
    "        total_windows = 0\n",
    "        for obs in features:\n",
    "          num_samples = len(features)\n",
    "          num_windows = int((num_samples - self.patch_size) / self.stride) + 1\n",
    "          window_remain = num_samples - self.patch_size\n",
    "          if window_remain % self.stride > 0:\n",
    "              num_windows += 1\n",
    "          total_windows += num_windows\n",
    "        self.num_steps = total_windows\n",
    "\n",
    "    def __call__(self):\n",
    "        num_observations = len(self.labels)\n",
    "        for obs_idx in range(num_observations):\n",
    "            features = tf.stack(self.features[obs_idx], axis=1) # np.column_stack\n",
    "            labels = self.labels[obs_idx]\n",
    "            for s,y in (self._compute_pcg_patches(features, labels)):\n",
    "              yield s, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate the Data Preparers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test_dp = PCGDataPreparer(patch_size=patch_size,\\n                     number_channels=nch,\\n                     stride=stride,\\n                     num_states=4)\\ntest_dp.set_features_and_labels(test[:, [1,2,3,4]], test[:, 5]) '"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_size = 64\n",
    "nch = 4\n",
    "stride = 32\n",
    "train_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "train_dp.set_features_and_labels(train[:, [1,2,3,4]], train[:, 5])\n",
    "\n",
    "val_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "val_dp.set_features_and_labels(val[:, [1,2,3,4]], val[:, 5])\n",
    "\n",
    "\"\"\" test_dp = PCGDataPreparer(patch_size=patch_size,\n",
    "                     number_channels=nch,\n",
    "                     stride=stride,\n",
    "                     num_states=4)\n",
    "test_dp.set_features_and_labels(test[:, [1,2,3,4]], test[:, 5]) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow Dataset and caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' test_dataset = get_data_from_generator(data_processor=test_dp,\\n                                                batch_size=BATCH_SIZE,\\n                                                patch_size=patch_size,\\n                                                number_channels=nch,\\n                                                number_classes=4,\\n                                                trainable=False) '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "def get_data_from_generator(*, data_processor, batch_size, patch_size, number_channels, number_classes, trainable=True):\n",
    "    data = tf.data.Dataset.from_generator(data_processor,\n",
    "                                          output_signature=(\n",
    "                                              tf.TensorSpec(shape=(patch_size, number_channels), dtype=tf.float32),\n",
    "                                              tf.TensorSpec(shape=(patch_size, number_classes), dtype=tf.float32))\n",
    "                                          )\n",
    "    if trainable:\n",
    "        data = data.shuffle(5000, reshuffle_each_iteration=True)\n",
    "        data.cache()\n",
    "    data = data.batch(batch_size)\n",
    "    data = data.prefetch(tf.data.AUTOTUNE)\n",
    "    return data\n",
    "\n",
    "train_dataset = get_data_from_generator(data_processor=train_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=True)\n",
    "\n",
    "\n",
    "val_dataset = get_data_from_generator(data_processor=val_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=False)\n",
    "\n",
    "\"\"\" test_dataset = get_data_from_generator(data_processor=test_dp,\n",
    "                                                batch_size=BATCH_SIZE,\n",
    "                                                patch_size=patch_size,\n",
    "                                                number_channels=nch,\n",
    "                                                number_classes=4,\n",
    "                                                trainable=False) \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Dropout, UpSampling1D, concatenate\n",
    "\n",
    "# TODO: provide u-net with one encoder layer only and suggest for them to\n",
    "# increase its size.\n",
    "def unet_pcg(nch, patch_size, dropout=0.0):\n",
    "    inputs = tf.keras.layers.Input(shape=(patch_size, nch))\n",
    "    conv1 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv1)\n",
    "    pool1 = tf.keras.layers.Dropout(dropout)(pool1)\n",
    "\n",
    "    conv2 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv2)\n",
    "    pool2 = tf.keras.layers.Dropout(dropout)(pool2)\n",
    "\n",
    "    conv3 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(conv3)\n",
    "    pool3 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv3)\n",
    "    pool3 = tf.keras.layers.Dropout(dropout)(pool3)\n",
    "\n",
    "    conv4 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(pool3)\n",
    "    conv4 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(conv4)\n",
    "    pool4 = tf.keras.layers.MaxPooling1D(pool_size=2)(conv4)\n",
    "    pool4 = tf.keras.layers.Dropout(dropout)(pool4)\n",
    "\n",
    "    conv5 = tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same')(pool4)\n",
    "    conv5 = tf.keras.layers.Conv1D(128, 3, activation='relu', padding='same')(conv5)\n",
    "\n",
    "    up6_prep = tf.keras.layers.UpSampling1D(size=2)(conv5)\n",
    "\n",
    "    up6 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(64, 2, padding='same')(up6_prep), conv4], axis=2)\n",
    "    up6 = tf.keras.layers.Dropout(dropout)(up6)\n",
    "    conv6 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(up6)\n",
    "    conv6 = tf.keras.layers.Conv1D(64, 3, activation='relu', padding='same')(conv6)\n",
    "\n",
    "    up7_prep = tf.keras.layers.UpSampling1D(size=2)(conv6)\n",
    "\n",
    "    up7 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(64, 2, padding='same')(up7_prep), conv3], axis=2)\n",
    "    up7 = tf.keras.layers.Dropout(dropout)(up7)\n",
    "    conv7 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(up7)\n",
    "    conv7 = tf.keras.layers.Conv1D(32, 3, activation='relu', padding='same')(conv7)\n",
    "\n",
    "    up8_prep = tf.keras.layers.UpSampling1D(size=2)(conv7)\n",
    "\n",
    "    up8 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(32, 2, padding='same')(up8_prep), conv2], axis=2)\n",
    "    up8 = tf.keras.layers.Dropout(dropout)(up8)\n",
    "    conv8 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(up8)\n",
    "    conv8 = tf.keras.layers.Conv1D(16, 3, activation='relu', padding='same')(conv8)\n",
    "\n",
    "    up9_prep = tf.keras.layers.UpSampling1D(size=2)(conv8)\n",
    "\n",
    "    up9 = tf.keras.layers.concatenate([tf.keras.layers.Conv1D(8, 2, padding='same')(up9_prep), conv1], axis=2)\n",
    "    up9 = tf.keras.layers.Dropout(dropout)(up9)\n",
    "    conv9 = tf.keras.layers.Conv1D(8, 3, activation='relu', padding='same')(up9)\n",
    "    conv9 = tf.keras.layers.Conv1D(8, 3, activation='tanh', padding='same')(conv9)\n",
    "\n",
    "    conv10 = tf.keras.layers.Conv1D(4, 1, activation='softmax')(conv9)\n",
    "\n",
    "    model = tf.keras.Model(inputs=[inputs], outputs=[conv10])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.metrics import Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2673/2673 [==============================] - 332s 123ms/step - loss: 0.5404 - categorical_accuracy: 0.8152 - precision: 0.8843 - recall: 0.7394 - val_loss: 0.4476 - val_categorical_accuracy: 0.8576 - val_precision: 0.8745 - val_recall: 0.8401\n",
      "Epoch 2/10\n",
      "2673/2673 [==============================] - 348s 130ms/step - loss: 0.3450 - categorical_accuracy: 0.8881 - precision: 0.9040 - recall: 0.8715 - val_loss: 0.4231 - val_categorical_accuracy: 0.8610 - val_precision: 0.8735 - val_recall: 0.8495\n",
      "Epoch 3/10\n",
      "2673/2673 [==============================] - 370s 138ms/step - loss: 0.3199 - categorical_accuracy: 0.8927 - precision: 0.9074 - recall: 0.8783 - val_loss: 0.4018 - val_categorical_accuracy: 0.8641 - val_precision: 0.8784 - val_recall: 0.8508\n",
      "Epoch 4/10\n",
      "2673/2673 [==============================] - 357s 133ms/step - loss: 0.3085 - categorical_accuracy: 0.8951 - precision: 0.9098 - recall: 0.8811 - val_loss: 0.4011 - val_categorical_accuracy: 0.8659 - val_precision: 0.8793 - val_recall: 0.8540\n",
      "Epoch 5/10\n",
      "2673/2673 [==============================] - 381s 142ms/step - loss: 0.3008 - categorical_accuracy: 0.8969 - precision: 0.9117 - recall: 0.8829 - val_loss: 0.3904 - val_categorical_accuracy: 0.8668 - val_precision: 0.8820 - val_recall: 0.8535\n",
      "Epoch 6/10\n",
      "2673/2673 [==============================] - 350s 131ms/step - loss: 0.2955 - categorical_accuracy: 0.8983 - precision: 0.9132 - recall: 0.8844 - val_loss: 0.3939 - val_categorical_accuracy: 0.8677 - val_precision: 0.8825 - val_recall: 0.8543\n",
      "Epoch 7/10\n",
      "2673/2673 [==============================] - 316s 118ms/step - loss: 0.2909 - categorical_accuracy: 0.8996 - precision: 0.9143 - recall: 0.8858 - val_loss: 0.3975 - val_categorical_accuracy: 0.8663 - val_precision: 0.8802 - val_recall: 0.8545\n",
      "Epoch 8/10\n",
      "2673/2673 [==============================] - 316s 118ms/step - loss: 0.2876 - categorical_accuracy: 0.9005 - precision: 0.9151 - recall: 0.8869 - val_loss: 0.3932 - val_categorical_accuracy: 0.8688 - val_precision: 0.8818 - val_recall: 0.8578\n",
      "Epoch 9/10\n",
      "2673/2673 [==============================] - 314s 117ms/step - loss: 0.2842 - categorical_accuracy: 0.9014 - precision: 0.9160 - recall: 0.8878 - val_loss: 0.3969 - val_categorical_accuracy: 0.8669 - val_precision: 0.8808 - val_recall: 0.8547\n",
      "Epoch 10/10\n",
      "2673/2673 [==============================] - 323s 120ms/step - loss: 0.2813 - categorical_accuracy: 0.9022 - precision: 0.9167 - recall: 0.8888 - val_loss: 0.3959 - val_categorical_accuracy: 0.8698 - val_precision: 0.8816 - val_recall: 0.8595\n"
     ]
    }
   ],
   "source": [
    "# tune hyperpararmeter, epochs, e optimizer\n",
    "# choose adequate metrics\n",
    "# loss crossentropy, others?\n",
    "checkpoint_path = './unet_weights/checkpoint.keras'\n",
    "EPOCHS = 10\n",
    "learning_rate = 1e-4\n",
    "model = unet_pcg(nch, patch_size)\n",
    "model.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy',\n",
    "                  metrics=['CategoricalAccuracy', 'Precision', 'Recall'])\n",
    "model_checkpoint = ModelCheckpoint(filepath=checkpoint_path, monitor='val_loss', save_best_only=True)\n",
    "history = model.fit(train_dataset,\n",
    "                    validation_data=val_dataset,\n",
    "                    epochs=EPOCHS,\n",
    "                    # steps_per_epoch = int(np.floor(train_dp.num_steps / BATCH_SIZE)),\n",
    "                    verbose=1,\n",
    "                    shuffle=True, callbacks=[model_checkpoint])\n",
    "\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference pipeline\n",
    "Collect the predictions of the U-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2673/2673 [==============================] - 28s 10ms/step\n",
      "745/745 [==============================] - 11s 15ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions_train = model.predict(train_dataset)\n",
    "val_test = model.predict(val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "signalProcessing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
